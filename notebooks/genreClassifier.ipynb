{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual Libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Libraries for feature extraction\n",
    "import librosa as lr\n",
    "import librosa.display\n",
    "\n",
    "# Libraries for audio playing\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Libraries for normalization and dimensionality reduction\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Libraries for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Libraries for model building and training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Libraries for model evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn import tree\n",
    "\n",
    "# Libraries for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D representation of the soundwaves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz_sample_path = '../dataset/genres_original/jazz/jazz.00020.wav'\n",
    "jazz_sample, sr = librosa.load(jazz_sample_path)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(jazz_sample, sr=sr)\n",
    "plt.title('Waveplot for Jazz Music 20')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time (s)')\n",
    "print(\"Jazz Music 20\")\n",
    "display(ipd.Audio(jazz_sample_path))\n",
    "\n",
    "pop_sample_path = \"../dataset/genres_original/pop/pop.00020.wav\"\n",
    "pop_sample, sr = librosa.load(pop_sample_path)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(pop_sample, sr=sr)\n",
    "plt.title(\"Waveplot for Pop Music 20\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "print(\"Pop Music 20\")\n",
    "display(ipd.Audio(pop_sample_path))\n",
    "\n",
    "rock_sample_path = \"../dataset/genres_original/rock/rock.00020.wav\"\n",
    "rock_sample, sr = librosa.load(rock_sample_path)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(rock_sample, sr=sr)\n",
    "plt.title(\"Waveplot for Rock Music 20\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "print(\"Rock Music 20\")\n",
    "display(ipd.Audio(rock_sample_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mel-frequency cepstral coefficients (MFCCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz_mfccs = librosa.feature.mfcc(y=jazz_sample, sr=sr)\n",
    "jazz_mfccs_normalized = librosa.util.normalize(jazz_mfccs, axis=1)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(jazz_mfccs_normalized, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC for Jazz Music 20') \n",
    "plt.ylabel('MFCC Coefficients')\n",
    "\n",
    "pop_mfccs = librosa.feature.mfcc(y=pop_sample, sr=sr)\n",
    "pop_mfccs_normalized = librosa.util.normalize(pop_mfccs, axis=1)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(pop_mfccs_normalized, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC for Pop Music 20')\n",
    "plt.ylabel('MFCC Coefficients')\n",
    "\n",
    "rock_mfccs = librosa.feature.mfcc(y=rock_sample, sr=sr)\n",
    "rock_mfccs_normalized = librosa.util.normalize(rock_mfccs, axis=1)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(rock_mfccs_normalized, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC for Rock Music 20')\n",
    "plt.ylabel('MFCC Coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz_centroid = librosa.feature.spectral_centroid(y=jazz_sample, sr=sr)[0]\n",
    "jazz_frames = range(len(jazz_centroid))\n",
    "jazz_t = librosa.frames_to_time(jazz_frames, sr=sr)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(jazz_t, jazz_centroid, color='b')\n",
    "plt.title('Spectral Centroid for Jazz Music 20')\n",
    "\n",
    "pop_centroid = librosa.feature.spectral_centroid(y=pop_sample, sr=sr)[0]\n",
    "pop_frames = range(len(pop_centroid))\n",
    "pop_t = librosa.frames_to_time(pop_frames, sr=sr)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(pop_t, pop_centroid, color='b')\n",
    "plt.title('Spectral Centroid for Pop Music 20')\n",
    "\n",
    "rock_centroid = librosa.feature.spectral_centroid(y=rock_sample, sr=sr)[0]\n",
    "rock_frames = range(len(rock_centroid))\n",
    "rock_t = librosa.frames_to_time(rock_frames, sr=sr)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(rock_t, rock_centroid, color='b')\n",
    "plt.title('Spectral Centroid for Rock Music 20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz_bandwidth = librosa.feature.spectral_bandwidth(y=jazz_sample, sr=sr)[0]\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(jazz_t, jazz_bandwidth, color='g')\n",
    "plt.title('Spectral Bandwidth for Jazz Music 20')\n",
    "\n",
    "pop_bandwidth = librosa.feature.spectral_bandwidth(y=pop_sample, sr=sr)[0]\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(pop_t, pop_bandwidth, color='g')\n",
    "plt.title('Spectral Bandwidth for Pop Music 20')\n",
    "\n",
    "rock_bandwidth = librosa.feature.spectral_bandwidth(y=rock_sample, sr=sr)[0]\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(rock_t, rock_bandwidth, color='g')\n",
    "plt.title('Spectral Bandwidth for Rock Music 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz_rolloff = librosa.feature.spectral_rolloff(y=jazz_sample, sr=sr)[0]\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(jazz_t, jazz_rolloff, color='r')\n",
    "plt.title('Spectral Rolloff for Jazz Music 20')\n",
    "\n",
    "pop_rolloff = librosa.feature.spectral_rolloff(y=pop_sample, sr=sr)[0]\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(pop_t, pop_rolloff, color='r')\n",
    "plt.title('Spectral Rolloff for Pop Music 20')\n",
    "\n",
    "rock_rolloff = librosa.feature.spectral_rolloff(y=rock_sample, sr=sr)[0]\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(rock_t, rock_rolloff, color='r')\n",
    "plt.title('Spectral Rolloff for Rock Music 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_crossings_jazz = librosa.feature.zero_crossing_rate(jazz_sample)[0]\n",
    "total_crossings_jazz = sum(zero_crossings_jazz)\n",
    "\n",
    "zero_crossings_pop = librosa.feature.zero_crossing_rate(pop_sample)[0]\n",
    "total_crossings_pop = sum(zero_crossings_pop)\n",
    "\n",
    "zero_crossings_rock = librosa.feature.zero_crossing_rate(rock_sample)[0]\n",
    "total_crossings_rock = sum(zero_crossings_rock)\n",
    "\n",
    "genres = ['Jazz', 'Pop', 'Rock']\n",
    "total_crossings = [total_crossings_jazz, total_crossings_pop, total_crossings_rock]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(genres, total_crossings, color=['blue', 'green', 'red'])\n",
    "plt.title('Total Zero Crossing Rate for Different Genres')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Total Zero Crossing Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rhythmic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz_tempo, _ = librosa.beat.beat_track(y=jazz_sample, sr=sr)\n",
    "pop_tempo, _ = librosa.beat.beat_track(y=pop_sample, sr=sr)\n",
    "rock_tempo, _ = librosa.beat.beat_track(y=rock_sample, sr=sr)\n",
    "\n",
    "jazz_tempo_val = (np.mean(jazz_tempo))\n",
    "pop_tempo_val = np.mean(pop_tempo)\n",
    "rock_tempo_val = np.mean(rock_tempo)\n",
    "\n",
    "print(f\"Jazz Tempo: {round(jazz_tempo_val)} BPM\")\n",
    "print(f\"Pop Tempo: {round(pop_tempo_val)} BPM\")\n",
    "print(f\"Rock Tempo: {round(rock_tempo_val)} BPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chroma features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz_chroma = librosa.feature.chroma_stft(y=jazz_sample, sr=sr)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(jazz_chroma, y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Chromagram for Jazz Music 20')\n",
    "\n",
    "pop_chroma = librosa.feature.chroma_stft(y=pop_sample, sr=sr)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(pop_chroma, y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Chromagram for Pop Music 20')\n",
    "\n",
    "rock_chroma = librosa.feature.chroma_stft(y=rock_sample, sr=sr)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(rock_chroma, y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Chromagram for Rock Music 20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Harmonic and precussive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz_harmony = librosa.effects.harmonic(y=jazz_sample)\n",
    "jazz_percussive = librosa.effects.percussive(y=jazz_sample)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(jazz_harmony, color='b')\n",
    "plt.plot(jazz_percussive, color='r')\n",
    "plt.title('Harmonic and Percussive for Jazz Music 20')\n",
    "\n",
    "pop_harmony = librosa.effects.harmonic(y=pop_sample)\n",
    "pop_percussive = librosa.effects.percussive(y=pop_sample)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(pop_harmony, color='b')\n",
    "plt.plot(pop_percussive, color='r')\n",
    "plt.title('Harmonic and Percussive for Pop Music 20')\n",
    "\n",
    "rock_harmony = librosa.effects.harmonic(y=rock_sample)\n",
    "rock_percussive = librosa.effects.percussive(y=rock_sample)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(rock_harmony, color='b')\n",
    "plt.plot(rock_percussive, color='r')\n",
    "plt.title('Harmonic and Percussive for Rock Music 20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_data = pd.read_csv('../dataset/features_3_sec.csv')\n",
    "music_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_cols = [col for col in music_data.columns if 'mean' in col]\n",
    "corr = music_data[spike_cols].corr()\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr, ax=ax)\n",
    "plt.title('Correlation between the features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal component analysis (PCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = music_data.drop(['filename', 'length', 'label'], axis=1)\n",
    "label = music_data['label']\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "scaled_data = standard_scaler.fit_transform(raw_data)\n",
    "df_scaled_data = pd.DataFrame(scaled_data, columns=raw_data.columns)\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "pca = PCA(n_components=2, random_state=random_state)\n",
    "pca_scaled_data = pca.fit_transform(df_scaled_data)\n",
    "print(pca.explained_variance_ratio_.sum())\n",
    "print(pca.n_features_in_)\n",
    "pca_df_scaled_data = pd.DataFrame(data=pca_scaled_data, columns=['PC1', 'PC2'])\n",
    "final_df = pd.concat([pca_df_scaled_data, label], axis=1)\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "sns.scatterplot(x='PC1', y='PC2', data=final_df, hue = 'label')\n",
    "plt.title('PCA on Standard Scaled Data')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing, training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    df_scaled_data, label, test_size=0.2, random_state=random_state\n",
    ")\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=random_state\n",
    "    )\n",
    "\n",
    "print(f\"Dataset: {len(df_scaled_data)}\")\n",
    "print(f\"Training set: {len(X_train)} ({round(len(X_train)/len(df_scaled_data)*100)}%)\")\n",
    "print(f\"Testing set: {len(X_test)} ({round(len(X_test)/len(df_scaled_data)*100)}%)\")\n",
    "print(f\"Validation set: {len(X_val)} ({round(len(X_val)/len(df_scaled_data)*100)}%)\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "true_labels = label_encoder.classes_\n",
    "print(\"True Labels: \", true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 200\n",
    "\n",
    "logistic_regression = LogisticRegression(max_iter=max_epochs, random_state=random_state, solver='lbfgs')\n",
    "logistic_regression.fit(X_train, y_train_encoded)\n",
    "\n",
    "train_pred = logistic_regression.predict(X_train)\n",
    "val_pred = logistic_regression.predict(X_val)\n",
    "test_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "train_acc_logistic = accuracy_score(y_train_encoded, train_pred)\n",
    "val_acc_logistic = accuracy_score(y_val_encoded, val_pred)\n",
    "test_acc_logistic = accuracy_score(y_test_encoded, test_pred)\n",
    "\n",
    "print(f\"Accuracy on Training Set: {round(train_acc_logistic * 100, 2)}%\")\n",
    "print(f\"Accuracy on Validation Set: {round(val_acc_logistic * 100, 2)}%\")\n",
    "print(f\"Accuracy on Testing Set: {round(test_acc_logistic * 100, 2)}%\")\n",
    "\n",
    "print(f\"Aantal iteraties per klasse: {logistic_regression.n_iter_}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_encoded, test_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=true_labels, yticklabels=true_labels)\n",
    "plt.title('Confusion Matrix Testing set')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "sgd_classifier = SGDClassifier(max_iter=max_epochs, random_state=random_state, learning_rate='constant', eta0=learning_rate)\n",
    "\n",
    "training_scores = []\n",
    "validation_scores = []\n",
    "testing_scores = []\n",
    "epochs = []\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    sgd_classifier.partial_fit(X_train, y_train_encoded, classes=np.unique(y_train_encoded))\n",
    "    train_score = sgd_classifier.score(X_train, y_train_encoded)\n",
    "    val_score = sgd_classifier.score(X_val, y_val_encoded)\n",
    "    test_score = sgd_classifier.score(X_test, y_test_encoded)\n",
    "    training_scores.append(train_score)\n",
    "    validation_scores.append(val_score)\n",
    "    testing_scores.append(test_score)\n",
    "    epochs.append(epoch)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Train accuracy = {train_score:.4f}, Validation accuracy = {val_score:.4f}, Test accuracy = {test_score:.4f}\")\n",
    "\n",
    "train_acc_sgd = accuracy_score(y_train_encoded, sgd_classifier.predict(X_train))\n",
    "val_acc_sgd = accuracy_score(y_val_encoded, sgd_classifier.predict(X_val))\n",
    "test_acc_sgd = accuracy_score(y_test_encoded, sgd_classifier.predict(X_test))\n",
    "\n",
    "print(f\"Accuracy on Training Set: {round(train_acc_sgd * 100, 2)}%\")\n",
    "print(f\"Accuracy on Validation Set: {round(val_acc_sgd * 100, 2)}%\")\n",
    "print(f\"Accuracy on Testing Set: {round(test_acc_sgd * 100, 2)}%\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_encoded, sgd_classifier.predict(X_test))\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=true_labels, yticklabels=true_labels)\n",
    "plt.title('Confusion Matrix Testing set')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(epochs, training_scores, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_scores, label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 10\n",
    "n_estimators = 100\n",
    "tree_count = list(range(1, n_estimators + 1, 5))\n",
    "training_scores = []\n",
    "val_scores = []\n",
    "testing_scores = []\n",
    "\n",
    "for trees in tree_count:\n",
    "    random_forest = RandomForestClassifier(n_estimators=trees, max_depth=max_depth, random_state=0)\n",
    "    random_forest.fit(X_train, y_train_encoded)\n",
    "    train_score = random_forest.score(X_train, y_train_encoded)\n",
    "    val_score = random_forest.score(X_val, y_val_encoded)\n",
    "    test_score = random_forest.score(X_test, y_test_encoded)\n",
    "\n",
    "    training_scores.append(train_score)\n",
    "    val_scores.append(val_score)\n",
    "    testing_scores.append(test_score)\n",
    "\n",
    "    if trees % 10 == 1:\n",
    "        print(f\" {trees} trees: Train accuracy = {training_scores[-1]:.4f}, Validation accuracy = {val_scores[-1]:.4f}, Test accuracy = {testing_scores[-1]:.4f}\")\n",
    "\n",
    "max_estimators = tree_count[np.argmax(val_scores)]\n",
    "print(f\"Optimal number of trees: {max_estimators}\")\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=max_estimators, max_depth=max_depth, random_state=random_state)\n",
    "random_forest.fit(X_train, y_train_encoded)\n",
    "\n",
    "train_acc_random = accuracy_score(y_train_encoded, random_forest.predict(X_train))\n",
    "val_acc_random = accuracy_score(y_val_encoded, random_forest.predict(X_val))\n",
    "test_acc_random = accuracy_score(y_test_encoded, random_forest.predict(X_test))\n",
    "\n",
    "print(f\"Accuracy on Training Set: {round(train_acc_random * 100, 2)}%\")\n",
    "print(f\"Accuracy on Validation Set: {round(val_acc_random * 100, 2)}%\")\n",
    "print(f\"Accuracy on Testing Set: {round(test_acc_random * 100, 2)}%\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_encoded, random_forest.predict(X_test))\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=true_labels, yticklabels=true_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(tree_count, training_scores, label=\"Training Accuracy\")\n",
    "plt.plot(tree_count, val_scores, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy vs Number of Trees in Random Forest\")\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(random_state=random_state), param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "\n",
    "svm_model = grid_search.best_estimator_\n",
    "\n",
    "train_acc_svm = accuracy_score(y_train_encoded, svm_model.predict(X_train))\n",
    "val_acc_svm = accuracy_score(y_val_encoded, svm_model.predict(X_val))\n",
    "test_acc_svm = accuracy_score(y_test_encoded, svm_model.predict(X_test))\n",
    "\n",
    "print(f\"The final model is a SVM model with C = {grid_search.best_params_['C']} and kernel = {grid_search.best_params_['kernel']}\")\n",
    "print(f\"Accuracy on Training Set: {round(train_acc_svm * 100, 2)}%\")\n",
    "print(f\"Accuracy on Validation Set: {round(val_acc_svm * 100, 2)}%\")\n",
    "print(f\"Accuracy on Testing Set: {round(test_acc_svm * 100, 2)}%\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_encoded, svm_model.predict(X_test))\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    conf_matrix, annot=True, fmt=\"d\", xticklabels=true_labels, yticklabels=true_labels\n",
    ")\n",
    "plt.title(\"Confusion Matrix for SVM\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "\n",
    "training_scores = []\n",
    "val_scores = []\n",
    "\n",
    "for C in param_grid['C']:\n",
    "    svm = SVC(C=C, kernel=grid_search.best_params_['kernel'], random_state=random_state)\n",
    "    svm.fit(X_train, y_train_encoded)\n",
    "    training_scores.append(svm.score(X_train, y_train_encoded))\n",
    "    val_scores.append(svm.score(X_val, y_val_encoded))\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(param_grid['C'], training_scores, label=\"Training Accuracy\")\n",
    "plt.plot(param_grid['C'], val_scores, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy vs C Parameter in SVM\")\n",
    "plt.xlabel(\"C Parameter\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "svm_rmse = -cross_val_score(svm_model, X_train, y_train_encoded, cv=10, scoring='neg_mean_squared_error')\n",
    "pd.Series(svm_rmse).describe()\n",
    "print(f\"Mean RMSE: {svm_rmse.mean()}\")\n",
    "print(f\"Standard Deviation of RMSE: {svm_rmse.std()}\")\n",
    "print(f\"Minimum RMSE: {svm_rmse.min()}\")\n",
    "print(f\"Maximum RMSE: {svm_rmse.max()}\")\n",
    "print(f\"RMSE for each fold: {svm_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_neighbors = 20\n",
    "k_values = list(range(1, max_neighbors + 1))\n",
    "weights = 'distance'\n",
    "\n",
    "training_scores = []\n",
    "val_scores = []\n",
    "testing_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights=weights)\n",
    "    knn.fit(X_train, y_train_encoded)\n",
    "    train_score = knn.score(X_train, y_train_encoded)\n",
    "    val_score = knn.score(X_val, y_val_encoded)\n",
    "    test_score = knn.score(X_test, y_test_encoded)\n",
    "\n",
    "    training_scores.append(train_score)\n",
    "    val_scores.append(val_score)\n",
    "    testing_scores.append(test_score)\n",
    "\n",
    "    if k % 2 == 0:\n",
    "        print(f\"K = {k}: Train accuracy = {train_score:.4f}, Validation accuracy = {val_score:.4f}, Test accuracy = {test_score:.4f}\")\n",
    "    \n",
    "best_k = 6\n",
    "print(f\"Best K: {best_k}\")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k, weights=weights)\n",
    "knn.fit(X_train, y_train_encoded)\n",
    "\n",
    "train_acc_knn = accuracy_score(y_train_encoded, knn.predict(X_train))\n",
    "val_acc_knn = accuracy_score(y_val_encoded, knn.predict(X_val))\n",
    "test_acc_knn = accuracy_score(y_test_encoded, knn.predict(X_test))\n",
    "\n",
    "print(f\"Accuracy on Training Set: {round(train_acc_knn * 100, 2)}%\")\n",
    "print(f\"Accuracy on Validation Set: {round(val_acc_knn * 100, 2)}%\")\n",
    "print(f\"Accuracy on Testing Set: {round(test_acc_knn * 100, 2)}%\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_encoded, knn.predict(X_test))\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=true_labels, yticklabels=true_labels)\n",
    "plt.title('Confusion Matrix for KNN')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(k_values, val_scores, marker='o')\n",
    "plt.title('Validation Accuracy vs Number of Neighbors')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = \"entropy\"\n",
    "max_depth = [5, 10, 15, 20, 25]\n",
    "class_weight = 'balanced'\n",
    "\n",
    "training_scores = []\n",
    "val_scores = []\n",
    "testing_scores = []\n",
    "\n",
    "for depth in max_depth:\n",
    "    decision_tree = DecisionTreeClassifier(criterion=criteria, max_depth=depth, class_weight=class_weight, random_state=random_state)\n",
    "    decision_tree.fit(X_train, y_train_encoded)\n",
    "    train_score = decision_tree.score(X_train, y_train_encoded)\n",
    "    val_score = decision_tree.score(X_val, y_val_encoded)\n",
    "    test_score = decision_tree.score(X_test, y_test_encoded)\n",
    "\n",
    "    training_scores.append(train_score)\n",
    "    val_scores.append(val_score)\n",
    "    testing_scores.append(test_score)\n",
    "\n",
    "    print(f\"Max Depth = {depth}: Train accuracy = {train_score:.4f}, Validation accuracy = {val_score:.4f}, Test accuracy = {test_score:.4f}\")\n",
    "\n",
    "best_depth = max_depth[np.argmax(val_scores)]\n",
    "print(f\"Best Max Depth: {best_depth}\")\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(criterion=criteria, max_depth=best_depth, class_weight=class_weight, random_state=random_state)\n",
    "decision_tree.fit(X_train, y_train_encoded)\n",
    "\n",
    "train_acc_decission = accuracy_score(y_train_encoded, decision_tree.predict(X_train))\n",
    "val_acc_decission = accuracy_score(y_val_encoded, decision_tree.predict(X_val))\n",
    "test_acc_decission = accuracy_score(y_test_encoded, decision_tree.predict(X_test))\n",
    "\n",
    "print(f\"Accuracy on Training Set: {round(train_acc_decission * 100, 2)}%\")\n",
    "print(f\"Accuracy on Validation Set: {round(val_acc_decission * 100, 2)}%\")\n",
    "print(f\"Accuracy on Testing Set: {round(test_acc_decission * 100, 2)}%\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_encoded, decision_tree.predict(X_test))\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=true_labels, yticklabels=true_labels)\n",
    "plt.title('Confusion Matrix for Decision Tree')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = \"log_loss\"\n",
    "learning_rate = 0.2\n",
    "n_estimators = 300\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(loss=loss, learning_rate=learning_rate, n_estimators=n_estimators, random_state=random_state)\n",
    "gradient_boosting.fit(X_train, y_train_encoded)\n",
    "\n",
    "train_acc_gradient = accuracy_score(y_train_encoded, gradient_boosting.predict(X_train))\n",
    "val_acc_gradient = accuracy_score(y_val_encoded, gradient_boosting.predict(X_val))\n",
    "test_acc_gradient = accuracy_score(y_test_encoded, gradient_boosting.predict(X_test))\n",
    "\n",
    "print(f\"Accuracy on Training Set: {round(train_acc_gradient * 100, 2)}%\")\n",
    "print(f\"Accuracy on Validation Set: {round(val_acc_gradient * 100, 2)}%\")\n",
    "print(f\"Accuracy on Testing Set: {round(test_acc_gradient * 100, 2)}%\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_encoded, gradient_boosting.predict(X_test))\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=true_labels, yticklabels=true_labels)\n",
    "plt.title('Confusion Matrix for Gradient Boosting')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(gradient_boosting.train_score_)\n",
    "plt.title('Loss over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['logistic_regression', 'sgd_classifier', 'random_forest', 'svm_model', 'knn', 'decision_tree', 'gradient_boosting']\n",
    "\n",
    "train_accuracies = [train_acc_logistic, train_acc_sgd, train_acc_random, train_acc_svm, train_acc_knn, train_acc_decission, train_acc_gradient]\n",
    "val_accuracies = [val_acc_logistic, val_acc_sgd, val_acc_random, val_acc_svm, val_acc_knn, val_acc_decission, val_acc_gradient]\n",
    "test_accuracies = [test_acc_logistic, test_acc_sgd, test_acc_random, test_acc_svm, test_acc_knn, test_acc_decission, test_acc_gradient]\n",
    "\n",
    "df_comparison = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Training Accuracy': train_accuracies,\n",
    "    'Validation Accuracy': val_accuracies,\n",
    "    'Testing Accuracy': test_accuracies\n",
    "})\n",
    "\n",
    "df_comparison = df_comparison.sort_values(by='Testing Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "bar_width = 0.25\n",
    "x = np.arange(len(models))\n",
    "\n",
    "plt.bar(x - bar_width, df_comparison['Training Accuracy'], width=bar_width, label='Training', color='#3498db', alpha=0.8)\n",
    "plt.bar(x, df_comparison['Validation Accuracy'], width=bar_width, label='Validation', color='#2ecc71', alpha=0.8)\n",
    "plt.bar(x + bar_width, df_comparison['Test Accuracy'], width=bar_width, label='Test', color='#e74c3c', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Models', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.title('Model Performance Comparison', fontsize=16)\n",
    "plt.xticks(x, df_comparison['Model'], rotation=45, ha='right', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.axhline(y=0.80, color='gray', linestyle='--', alpha=0.7)\n",
    "plt.text(len(models)-1, 0.81, 'Benchmark (80%)', fontsize=10)\n",
    "\n",
    "for i, model in enumerate(df_comparison['Model']):\n",
    "    plt.text(i, df_comparison['Test Accuracy'][i] + 0.01, f\"{df_comparison['Test Accuracy'][i]:.4f}\", \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "df_heatmap = df_comparison.copy()\n",
    "df_heatmap['Train-Test Gap'] = df_heatmap['Training Accuracy'] - df_heatmap['Test Accuracy']\n",
    "df_heatmap = df_heatmap[['Model', 'Training Accuracy', 'Validation Accuracy', 'Test Accuracy', 'Train-Test Gap']]\n",
    "df_heatmap = df_heatmap.set_index('Model')\n",
    "\n",
    "sns.heatmap(df_heatmap, annot=True, cmap='YlGnBu', fmt='.4f', linewidths=0.5)\n",
    "plt.title('Model Performance Metrics', fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the model based on performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'rbf'\n",
    "C_value = 10\n",
    "gamma = 'scale'\n",
    "final_svm_model = SVC(C=C_value, kernel=kernel, gamma=gamma, random_state=random_state)\n",
    "final_model = final_svm_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "print(f\"The final model is a SVM model with C = {C_value} and kernel = {kernel}\")\n",
    "\n",
    "print(f\"The accuracy of the model on the test data is {round(final_model.score(X_test, y_test_encoded)*100,2)}%\")\n",
    "\n",
    "y_true = y_test_encoded\n",
    "y_pred = final_model.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=true_labels, yticklabels=true_labels)\n",
    "plt.title('Confusion Matrix for Final SVM Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "MODEL_DIR = os.path.join('..', 'models')\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "model_filename = os.path.join(MODEL_DIR, 'svm_final_model.sav')\n",
    "pickle.dump(final_model, open(model_filename, 'wb'))\n",
    "print(f\"Model saved as {model_filename}\")\n",
    "\n",
    "label_filename = os.path.join(MODEL_DIR, 'label_encoder.sav')\n",
    "pickle.dump(label_encoder, open(label_filename, 'wb'))\n",
    "print(f\"Label Encoder saved as {label_filename}\")\n",
    "\n",
    "scaler_filename = os.path.join(MODEL_DIR, 'standard_scaler.sav')\n",
    "pickle.dump(standard_scaler, open(scaler_filename, 'wb'))\n",
    "print(f\"Standard Scaler saved as {scaler_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
